# Model Evaluation : 
__Model Evaluation is an integral part of the model development process.
It helps to find the best model that represents our data and how well the chosen model will work in the future. 
Evaluating model performance with the data used for training is not acceptable in data science because it can easily generate overoptimistic and overfitted models. 
There are two methods of evaluating models in data science, Hold-Out and Cross-Validation. 
To avoid overfitting, both methods use a test set (not seen by the model) to evaluate model performance.__
