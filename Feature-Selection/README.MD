# Feature Selection :
* Feature Selection is one of the core concepts in machine learning which hugely impacts the performance of your model. 
The data features that you use to train your machine learning models have a huge influence on the performance you can achieve.
* Irrelevant or partially relevant features can negatively impact model performance.

* __Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in.__
* Having ```irrelevant``` features in your data can __decrease__ the accuracy of the models and make your model learn based on irrelevant features.

# How to select these most important features ?
### Feature Selection Methods:
1. Univariate Selection
2. Feature Importance
3. Correlation Matrix with Heatmap
### Benifits :
* __Reduces Overfitting :__ Less redundant data means less opportunity to make decisions based on noise.
* __Improves Accuracy :__ Less misleading data means modeling accuracy improves.
* __Reduces Training Time :__ fewer data points reduce algorithm complexity and algorithms train faster.
